name: Swift CI
on:
  pull_request:
  push: 
    branches: ['main']

defaults:
  run:
    shell: bash

permissions:
  contents: read

jobs:
  format:
    runs-on: macos-latest
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@0080882f6c36860b6ba35c610c98ce87d4e2f26f # v2.10.2
        with:
          egress-policy: audit

      - name: Checkout Code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Install swift-format
        run: brew install swift-format

      - name: Format
        run: swift format lint --strict --configuration .swift-format.json --recursive --parallel Sources/ Tests/ Examples/ Package.swift

  build:
    strategy:
      matrix:
        swift: ["5.9"]
        os: [macos-13]

    runs-on: ${{ matrix.os }}
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@0080882f6c36860b6ba35c610c98ce87d4e2f26f # v2.10.2
        with:
          egress-policy: audit

      - name: Setup Swift
        uses: swift-actions/setup-swift@3aed395c5397f62deb91d8fe7af1418a9ae4d16f # v2.1.0
        with:
          swift-version: ${{ matrix.swift }}

      - name: Checkout Code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Cache
        uses: actions/cache@1bd1e32a3bdc45362d1e726936510720a7c30a57 # v4.2.0
        with:
          path: sdk/swift/.build
          key: ${{ runner.os }}-${{ matrix.swift }}-spm-${{ github.job }}-${{ hashFiles('**/Package.resolved') }}
          restore-keys: |
            ${{ runner.os }}-${{ matrix.swift }}-spm-

      - name: Build
        run: swift build

  test:
    strategy:
      matrix:
        swift: ["5.9"]
        os: [macos-13]

    needs: [build]
    runs-on: ${{ matrix.os }}
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@0080882f6c36860b6ba35c610c98ce87d4e2f26f # v2.10.2
        with:
          egress-policy: audit

      - name: Setup Swift
        uses: swift-actions/setup-swift@3aed395c5397f62deb91d8fe7af1418a9ae4d16f # v2.1.0
        with:
          swift-version: ${{ matrix.swift }}

      - name: Checkout Code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Cache Code
        uses: actions/cache@1bd1e32a3bdc45362d1e726936510720a7c30a57 # v4.2.0
        with:
          path: sdk/swift/.build
          key: ${{ runner.os }}-${{ matrix.swift }}-spm-${{ github.job }}-${{ hashFiles('**/Package.resolved') }}
          restore-keys: |
            ${{ runner.os }}-${{ matrix.swift }}-spm-

      # ---------- Tooling ----------
      - name: Install Homebrew packages (Colima, Docker CLI, kind, kubectl, Helm, jq, coreutils)
        shell: bash
        run: |
          brew update
          # Install Colima + Docker CLI and explicit deps (lima/qemu)
          brew install colima docker lima qemu
          # k8s toolchain + utilities
          brew install kind kubectl helm jq coreutils
          # prep the mount Colima warns about
          mkdir -p /tmp/colima

      - name: Install & start Docker Desktop (headless)
        shell: bash
        run: |
          brew install --cask docker
          # launch the app; it runs headless on Actions
          open -a Docker
          echo "Waiting for Docker to become ready..."
          for i in {1..60}; do
            if docker system info >/dev/null 2>&1; then
              break
            fi
            sleep 5
          done
          docker info
          docker version

      # ---------- Node.js for Solo ----------
      - name: Use Node 20.18.x
        uses: actions/setup-node@v4
        with:
          node-version: "20.18.x"
      - name: Verify Node
        run: |
          node -v
          npm -v

      # ---------- Solo CLI ----------
      - name: Install Solo CLI (v0.38.x)
        run: |
          npm install -g @hashgraph/solo@0.38
          solo --version

      # ---------- Create a local K8s cluster with kind ----------
      - name: Create kind cluster
        shell: bash
        run: |
          kind create cluster -n "${SOLO_CLUSTER_NAME}" --image "${KIND_IMAGE}"
          kubectl cluster-info --context "kind-${SOLO_CLUSTER_NAME}"

      # ---------- Solo initialization & deployment (minimal path) ----------
      - name: Solo init
        shell: bash
        run: |
          # Clean artifacts if re-running the job (optional safety)
          for cluster in $(kind get clusters); do kind delete cluster -n "$cluster"; done || true
          rm -rf ~/.solo || true
          # Recreate the cluster after cleanup (when above deletion occurred)
          kind get clusters | grep -qx "${SOLO_CLUSTER_NAME}" || kind create cluster -n "${SOLO_CLUSTER_NAME}" --image "${KIND_IMAGE}"
          # Initialize solo (checks dependencies incl. helm)
          solo init

      - name: Connect cluster-ref and create deployment
        shell: bash
        run: |
          solo cluster-ref connect --cluster-ref "kind-${SOLO_CLUSTER_NAME}" --context "kind-${SOLO_CLUSTER_NAME}"
          solo deployment create -n "${SOLO_NAMESPACE}" --deployment "${SOLO_DEPLOYMENT}"

      - name: Add a cluster (1 consensus node)
        shell: bash
        run: |
          solo deployment add-cluster \
            --deployment "${SOLO_DEPLOYMENT}" \
            --cluster-ref "kind-${SOLO_CLUSTER_NAME}" \
            --num-consensus-nodes 1

      - name: Generate node keys (gossip + TLS)
        shell: bash
        run: |
          solo node keys --gossip-keys --tls-keys --deployment "${SOLO_DEPLOYMENT}"
          ls -la ~/.solo/cache/keys || true

      - name: Setup cluster shared components
        shell: bash
        run: |
          solo cluster-ref setup -s "${SOLO_CLUSTER_SETUP_NAMESPACE}"

      - name: Deploy network (consensus node only)
        shell: bash
        run: |
          # This charts install may take a bitâ€”prints will help you see progress
          set -x
          solo network deploy --deployment "${SOLO_DEPLOYMENT}" --cluster-ref "kind-${SOLO_CLUSTER_NAME}"

      - name: Set up Hedera node
        shell: bash
        run: |
          solo node setup --deployment "${SOLO_DEPLOYMENT}" --cluster-ref "kind-${SOLO_CLUSTER_NAME}"

      - name: Start Hedera node(s)
        shell: bash
        run: |
          solo node start --deployment "${SOLO_DEPLOYMENT}" --cluster-ref "kind-${SOLO_CLUSTER_NAME}"

      - name: Wait for pods to become Ready
        shell: bash
        run: |
          # Wait up to ~10 minutes for all pods in the Solo namespace to be ready
          kubectl -n "${SOLO_NAMESPACE}" get pods
          end=$((SECONDS+600))
          while [ $SECONDS -lt $end ]; do
            not_ready=$(kubectl -n "${SOLO_NAMESPACE}" get pods --no-headers | awk '{print $2}' | grep -v '^1/1$' || true)
            if [ -z "$not_ready" ]; then
              echo "All pods ready."
              kubectl -n "${SOLO_NAMESPACE}" get pods -o wide
              exit 0
            fi
            echo "Pods not ready yet; sleeping 10s..."
            sleep 10
          done
          echo "Timed out waiting for pods."
          kubectl -n "${SOLO_NAMESPACE}" get pods -o wide
          exit 1

      # ---------- (Optional) Show endpoints / basic sanity ----------
      - name: Show services and endpoints
        if: always()
        shell: bash
        run: |
          echo "Solo services in ${SOLO_NAMESPACE}:"
          kubectl -n "${SOLO_NAMESPACE}" get svc
          echo "Solo endpoints (if any):"
          kubectl -n "${SOLO_NAMESPACE}" get endpoints

      # ---------- Cleanup on failure to avoid runner leftovers ----------
      - name: Cleanup kind cluster (on failure)
        if: failure()
        run: |
          kind delete cluster -n "${SOLO_CLUSTER_NAME}" || true
          colima stop || true
          # Dump colima logs
          LOGDIR="$HOME/.colima/_lima/colima"
          echo "=== ha.stderr.log ===" ; cat "$LOGDIR/ha.stderr.log" || true
          echo "=== serial logs ==="   ; cat "$LOGDIR"/serial*.log   || true

      - name: Test
        run: swift test
